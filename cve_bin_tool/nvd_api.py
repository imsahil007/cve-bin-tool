# Copyright (C) 2021 Intel Corporation
# SPDX-License-Identifier: GPL-3.0-or-later

"""
Retrieval access and of NVD entries using NVD Automatic CVE Retrieval
"""

import asyncio
import gzip
import json
import math
import os
from datetime import datetime
from logging import Logger
from typing import Union

import aiohttp
from rich.progress import Progress, track

from cve_bin_tool.async_utils import RateLimiter
from cve_bin_tool.error_handler import ErrorMode, NVDServiceError
from cve_bin_tool.log import LOGGER

NVD_FILENAME_TEMPLATE = "nvdcve-1.1-{}.json.gz"
DISK_LOCATION_DEFAULT = os.path.join(os.path.expanduser("~"), ".cache", "cve-bin-tool")


FEED = "https://services.nvd.nist.gov/rest/json/cves/1.0"

NVD_CVE_STATUS = "https://nvd.nist.gov/rest/public/dashboard/statistics"

PAGESIZE = 2000
MAX_FAIL = 5
# Interval in seconds between successive requests
INTERVAL_PERIOD = 2


def filter_by_id(cve, update_data):
    """Function to filter out duplicate CVE entries in case of incremental update"""
    cve_id = cve["cve"]["CVE_data_meta"]["ID"]

    return all(
        cve_id != update_cve["cve"]["CVE_data_meta"]["ID"] for update_cve in update_data
    )


class NVD_API:
    def __init__(
        self,
        logger: Logger = LOGGER.getChild("NVD_API"),
        feed=FEED,
        session=None,
        page_size: int = PAGESIZE,
        max_fail: int = MAX_FAIL,
        interval: int = INTERVAL_PERIOD,
        outdir=DISK_LOCATION_DEFAULT,
        error_mode: ErrorMode = ErrorMode.TruncTrace,
    ):
        self.logger = logger or LOGGER.getChild(self.__class__.__name__)
        self.feed = feed
        self.session = session
        self.params = dict()
        self.page_size = page_size
        self.max_fail = max_fail
        self.interval = interval
        self.outdir = outdir
        self.error_mode = error_mode
        self.NVDCVE_FILENAME_TEMPLATE = NVD_FILENAME_TEMPLATE
        self.total_results = -1
        self.failed_count = 0
        self.all_cve_entries = []

    @staticmethod
    def convert_date_to_nvd_date(date: datetime) -> str:
        """Returns a datetime string of NVD recognized date format"""
        utc_date = date.utcnow().strftime("%Y-%m-%dT%H:%M:%S:%f")[:-3]
        return f"{utc_date} UTC-00:00"

    @staticmethod
    async def nvd_count_metadata(session):
        """Returns CVE Status count from NVD"""
        cve_count = dict()
        async with await session.get(
            NVD_CVE_STATUS,
            params={"reporttype": "countsbystatus"},
            raise_for_status=True,
        ) as response:
            data = await response.json()
            for key in data["vulnsByStatusCounts"]:
                cve_count[key["name"]] = int(key["count"])
        return cve_count

    async def get_nvd_params(
        self,
        time_of_last_update: Union[datetime, None] = None,
    ):
        """
        Initialize NVD request parameters
        """
        if time_of_last_update:
            # Fetch all cves from this date (even the updated ones)
            self.params["modStartDate"] = self.convert_date_to_nvd_date(
                time_of_last_update
            )
            self.logger.info(self.params["modStartDate"])
            self.logger.info(time_of_last_update)
            self.params["includeMatchStringChange"] = json.dumps(True)

            # Check modified strings inside CVEs as well

        self.params["startIndex"] = 0
        self.params["resultsPerPage"] = self.page_size

        if not self.session:
            connector = aiohttp.TCPConnector()
            self.session = RateLimiter(
                aiohttp.ClientSession(connector=connector, trust_env=True)
            )

        self.logger.debug("Fetching metadata from NVD...")

        cve_count = await self.nvd_count_metadata(self.session)
        self.total_results = cve_count["Total"] - cve_count["Rejected"]
        self.logger.info(f"Total {self.total_results} entries available")

    async def load_nvd_request(self, start_index):
        """Get single NVD request and update year_wise_data list which contains list of all CVEs"""

        param_dict = self.params.copy()
        param_dict["startIndex"] = start_index

        fetched_data = None
        while fetched_data is None:
            try:
                async with await self.session.get(
                    self.feed,
                    params=param_dict,
                    raise_for_status=True,
                ) as response:
                    if response.status == 200:
                        fetched_data = await response.json()

                        self.all_cve_entries.extend(fetched_data["result"]["CVE_Items"])

                        # await asyncio.sleep(0)
                    elif response.status == 503:
                        raise NVDServiceError(self.params["modStartDate"])
                    else:
                        self.failed_count += 1
                        if self.failed_count == self.max_fail:
                            self.logger.info(
                                f"Pausing requests for {self.interval} seconds"
                            )
                            self.failed_count = 0
                            await asyncio.sleep(self.interval)
                        else:
                            await asyncio.sleep(1)

            except aiohttp.ClientResponseError as error:
                self.logger.debug(f"Failed to connect to NVD {error}")
                self.logger.debug(f"Pausing requests for {self.interval} seconds")
                await asyncio.sleep(self.interval)

    async def get(self):
        """Calls load_nvd_request() multiple times to fetch all NVD feeds"""

        nvd_requests = [
            self.load_nvd_request(index * self.page_size)
            for index in range(
                0, 1 + int(math.ceil(self.total_results / self.page_size))
            )
        ]

        total_tasks = len(nvd_requests)
        # error_mode.value will only be greater than 1 if quiet mode.
        if self.error_mode.value > 1:
            iter_tasks = track(
                asyncio.as_completed(nvd_requests),
                description="Downloading Feeds from NVD...",
                total=total_tasks,
            )
        else:
            iter_tasks = asyncio.as_completed(nvd_requests)

        for task in iter_tasks:
            await task
        self.logger.info(
            "Updating cache using fetched NVD data. This will take some minutes..."
        )
